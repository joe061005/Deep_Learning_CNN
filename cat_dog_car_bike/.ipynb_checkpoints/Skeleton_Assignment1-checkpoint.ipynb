{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Assignment 1. Cat, Dog, Car or Bike?\n",
    "\n",
    "**Dataset:** You are provided with a dataset which contains more than 3000 pictures with either a cat, a dog, a motorbike or a car. The dataset has already been split in training, test and validation sets. Your task is to build and train a CNN which is able to recognize which object is depicted in the picture. To this end, you must use and change the code we presented during our tutorial. You should copy and unzip the dataset in your local directory (do not change the name of the directory), namely the same directory where this jupyter notebook is going to be stored. \n",
    "\n",
    "**Python and Keras version.** We recommend you to use Python 3.6 (there might be some incompatibility issues between keras and the most recent versions of Python). We also recommend to use TensorFlow 2.1.0 and Keras 2.3.1, which are the settings we used to test everything. You can find the documentation for keras at the following address https://keras.io/layers/convolutional/.\n",
    "\n",
    "**What to submit:** You should post on moodle this jupyter notebook filled will all the answers to the questions, the Python code and the plots. Do not change any part of the code that is provided to you, unless explicitly asked. The answers to the questions should be provided below at the end of the notebook. You should also post on moodle the model for question 5 (name of the model \"modelQ5.h1\"). In case your model has size larger than 100MB please provide a link to Google Drive or other storage services. **Important**: For each question you will get 0 points if the code or any of the plots are missing or the code is not correct.\n",
    "\n",
    "**Image Size** You should use image size **32x32** for the first three questions. You can use higher resolutions for questions 4 and 5. We kindly ask you to use your machine whenever possible, in order to avoid the GPU farm to be overwhelmed. \n",
    "\n",
    "**GPU Farm**: You will have access to the HKU GPU farm to do this assignment. Additional info on how to use it is contained in a separate document provided with the assignement. Please use this only for questions 4 and 5. We will show how to use GPU Farm below. \n",
    "\n",
    "If you have any questions, you can join the WhatsApp group to discuss together. Also Assignment1 tutorial video link will be available in this group. https://chat.whatsapp.com/GPVWwxFa1NX1ci3ktCnMww\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use GPU Farm.\n",
    "\n",
    "For **windows** users to use ssh to the GPU Farm, you should download **MobaXterm** first. For mac and linux users, you can use the terminal directly.\n",
    "\n",
    "1.Connect to HKU Network via HKU VPN with your HKU Portal account\n",
    "https://its.hku.hk/services/network-connectivity/hkuvpn/\n",
    "\n",
    " \n",
    "\n",
    "2.The instructions for Accessing GPU Farm are on this page:\n",
    "https://www.cs.hku.hk/gpu-farm/quickstart\n",
    "\n",
    "For GPU Farm Phase 1, click the following link and login with your CS computing account.\n",
    "https://intranet.cs.hku.hk/gpufarm_acct/\n",
    "\n",
    "\n",
    "But actually, GPU Farm 1 is not stable. Alternatively, we strongly recommend you use GPU Farm Phase 2, you may try with your HKU Portal account.\n",
    "https://intranet.cs.hku.hk/gpufarm_acct_cas/ for application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install.md\n",
    "You should download and install **anaconda** first. To create the environment in Anaconda prompt, enter the following command (without the $ symbol). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ conda create -n py3.6_tf2.1_ke2.3.1 python=3.6\n",
    "$ conda activate py3.6_tf2.1_ke2.3.1\n",
    " \n",
    "$ pip install tensorflow==2.1.0\n",
    "$ pip install keras==2.3.1\n",
    "$ pip install matplotlib\n",
    "$ pip install jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n",
    "We have prepared the dataset for you. You should download it in:\n",
    "https://drive.google.com/file/d/1wTuQyTtHCQq-xawNkIUEWT-ga1FrVOrj/view?usp=sharing\n",
    "\n",
    "Unzip the file and the folder structure is shown as:\n",
    "```\n",
    "Assign1\n",
    "├── Skeleton_Assignment1.ipynb\n",
    "├── cat_dog_car_bike\n",
    "│   ├── train\n",
    "│   ├── val\n",
    "│   ├── test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1 (CNN Architecture) \n",
    "\n",
    "Define a CNN architecture with the following layers stacked on top of each other in the following order:\n",
    "1. A convolutional layer with 32 5 × 5 filters. \n",
    "2. A max Pooling Layer with size 2 × 2.\n",
    "3. A convolutional layer with 64 5 × 5 filters. \n",
    "4. A max Pooling Layer with size 2 × 2.\n",
    "5. A convolutional layer with 64 3 × 3 filters. \n",
    "6. A max Pooling Layer with size 2 × 2.\n",
    "7. A convolutional layer with 64 3 × 3 filters. \n",
    "7. A max Pooling Layer with size 2 × 2.\n",
    "9. A dense layer with 256 units.\n",
    "10. A dense layer with k units and softmax (aka cross entropy) loss function.\n",
    "\n",
    "Use the sigmoid activation function for all layers but the last one which uses the softmax. Use default values for the parameters which are not specified above.\n",
    "\n",
    "a) <font color=Red>[5pts]</font> Determine the right value for k and write the value for k you use at the end of the notebook. Write the code to solve a) in the cell below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='sigmoid',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "\n",
    "# write your own code for a) here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) <font color=Red>[5pts]</font> The architecture defined above cannot be built because of an error. You should fix such an error **without changing the number of convolutional, pooling or dense layers, the number of filters, the size of the filters, or the number of units**. Write at the end of the notebook which strategy did you use and write the code to solve b) in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='sigmoid',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "\n",
    "\n",
    "# write your own code for b) here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (Training a small CNN from scratch)\n",
    "\n",
    "We are now considering a different CNN architecture specified in the code below. **Fill the missing parts (there is a comment (#) specifying which parts must be filled)**. After that, you should train such a CNN using the following values for the parameters:\n",
    "\n",
    "- loss function = crossentropy;\n",
    "- optimizer RMSprop with learning rate = 0.1;\n",
    "- metrics = accuracy;\n",
    "- Batch size for the training/validation generators = 20; \n",
    "- epochs = 30.\n",
    "\n",
    "*Write your codes below and some answers at the end of the notebook again. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='sigmoid',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# something is missing here \n",
    "model.add(layers.Dense(512, activation='sigmoid'))\n",
    "model.add(layers.Dense(k, activation='softmax')) # replace k with the corresponding value\n",
    "\n",
    "model.compile( # fill this part ...\n",
    "    \n",
    "   \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './cat_dog_car_bike'\n",
    "train_dir= os.path.join(base_dir, 'train')\n",
    "validation_dir= os.path.join(base_dir, 'val')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(32, 32),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(32, 32),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) <font color=Red>[5pts]</font> What is the main problem for your model?\n",
    "\n",
    "1. Overfitting\n",
    "2. Underfitting\n",
    "\n",
    "Write your answer below at the end of the notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) <font color=Red>[5pts]</font> **Without changing the learning rate**, change one hyperparameter so as to improve the training error. Which hyperparameters did you change? \n",
    "\n",
    "*Write your codes below and some answers at the end of the notebook again. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "# fill this part\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (Optimize the learning rate) \n",
    "\n",
    "a)<font color=Red>[10pts]</font> Determine an interval [a,b] of possible values for the learning rate, which is “wide enough”. In particular, you should try to guarantee that **your interval contains an optimal value for the learning rate**. At the same time the interval that you provided should not be too wide, due to efficiency reasons. In particular, your interval [a,b] should be such that $\\frac{b}{a} \\leq 10$.\n",
    "\n",
    "b)<font color=Red>[15pts]</font> Provide a \"good\" value for the learning rate. In particular, the training error should become smaller than 0.1 within 30 epochs. \n",
    "\n",
    "*Write your codes below and some answers at the end of the notebook again. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "# fill this part\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4 (Transfer Learning) <font color=Red>[25pts]</font>\n",
    "\n",
    "Use the VGG16 as feature extractor with data augmentation (i.e. remove the top layer and freeze the VGGnet). You should try to achieve a **validation accuracy of at least 94\\%**. Report the accuracy of your model on the test set.\n",
    "\n",
    "*Write your codes below and some answers at the end of the notebook again. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "# fill this part\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (Open Question) <font color=Red>[25pts]</font>\n",
    "\n",
    "Use any of the techniques we saw during our course so as to improve the validation accuracy of your CNN. You should try to achieve a **validation accuracy of at least 96\\%** and in any case better than the validation accuracy provided in question 4. Report the accuracy of your model on the test set.Your model should have **max size of 300Mb**.\n",
    "\n",
    "*Write your codes below and some answers at the end of the notebook again. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "# fill this part\n",
    "\n",
    "\n",
    "model.save('modelQ5.h1') #important do not change the name of the model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "\n",
    "Write your answers for these questions below in the box.\n",
    "\n",
    "Question 1\n",
    "* a) What is the right value of k? \n",
    "* b) How did you fix the error in the architecture?\n",
    "\n",
    "Question 2\n",
    "* a) There was a problem of underfitting or overfitting?\n",
    "* b) Which hyperparameter did you change?\n",
    "\n",
    "Question 3\n",
    "* a) which interval for the learning rate did you consider?\n",
    "* b) which value for the learning rate did you consider?\n",
    "\n",
    "Question 4\n",
    "* a) what is the validation accuracy of the modified VGG16 model?\n",
    "* b) what is the test accuracy of the modified VGG16 model?\n",
    "\n",
    "Question 5\n",
    "* a) what is the validation accuracy of your own model?\n",
    "* b) what is the test accuracy of your own model?\n",
    "* c) provide your model with a cloud link (eg: Google Drive, One Drive or Baiduyun Drive)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
